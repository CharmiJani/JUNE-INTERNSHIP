{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlJxAErYW0iGC33w2czaHY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Importing Dependencies\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier , DescisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","#Loading dataset to Pandas DataFrame\n","wine_data = pd.read_csv('winequalityN.csv')\n","\n","\n","#Drop the 'type' column if it exists\n","if 'type' in wine_data.columns:\n","    wine_data = wine_data.drop('type', axis=1)\n","\n","#Number of rows and columns in the Dataset\n","wine_data.shape\n","\n","#Check missing values in the dataset\n","wine_data.isnull().sum()\n","\n","#Handle missing values by imputing with the mean\n","columns_to_impute = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'pH', 'sulphates']\n","for column in columns_to_impute:\n","    wine_data[column].fillna(wine_data[column].mean(), inplace=True)\n","\n","#Statistical measures of the dataset\n","wine_data.describe()\n","\n","#Volatile acidity vs Quality\n","plt.figure(figsize=(4, 4))\n","sns.barplot(x='quality', y='volatile acidity', data=wine_data, palette=\"inferno\")\n","plt.title('Volatile Acidity vs Quality')\n","plt.show()\n","\n","#Citric acid vs Quality\n","plot = plt.figure(figsize=(4,4))\n","sns.barplot(x='quality' , y='citric acid' , data=wine_data, palette=\"magma\")\n","plt.title('Citric Acid vs Quality')\n","plt.show()\n","\n","#Chlorides vs Quality\n","plot = plt.figure(figsize=(4,4))\n","sns.barplot(x='quality' , y='chlorides' , data=wine_data, palette=\"dark\")\n","plt.title('Chlorides vs Quality')\n","plt.show()\n","\n","#Alcohol vs Quality\n","plot = plt.figure(figsize=(4,4))\n","sns.barplot(x='quality' , y='alcohol' , data=wine_data, palette=\"viridis\")\n","plt.title('Alchol vs Quality')\n","plt.show()\n","\n","#pH vs Quality\n","plot = plt.figure(figsize=(4,4))\n","sns.barplot(x='quality' , y='pH' , data=wine_data, palette=\"bright\")\n","plt.title('pH vs Quality')\n","plt.show()\n","\n","#Label Binarization/Encoding\n","Y = wine_data['quality'].apply(lambda y_value: 1 if y_value>=7 else 0)\n","print(Y)\n","\n","X= wine_data.drop('quality',axis=1)\n","print(X)\n","#Train and Test Split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n","\n","#Model Training:\n","\n","#Random Forest Classifier\n","model = RandomForestClassifier()\n","model.fit(X_train, Y_train)\n","\n","#Model Evualuation:\n","\n","#Accuracy Score\n","X_test_prediction = model.predict(X_test)\n","test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n","print('Accuracy : ', test_data_accuracy)\n","\n","input_data = (6.3,0.3,0.34,1.6,0.049,14,132,0.994,3.3,0.49,9.5)\n","\n","#changing the input data into numpy array\n","input_data_as_numpy_array = np.asarray(input_data)\n","\n","#reshape the data as we are predicting the label for only one instance\n","input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n","\n","prediction = model.predict(input_data_reshaped)\n","print(prediction)\n","\n","if (prediction[0]==1):\n","  print('Good Quality Wine')\n","else:\n","  print('Bad Quality Wine')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"A3lAZtNJD9mU","executionInfo":{"status":"error","timestamp":1718955621715,"user_tz":-330,"elapsed":1347,"user":{"displayName":"SE_17_Charmi Jani","userId":"03847520836382925686"}},"outputId":"7ccdb953-bf01-4323-c931-4b1b28d3127e"},"execution_count":34,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'DescisionTreeClassifier' from 'sklearn.ensemble' (/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-4f8273a7ccd5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mDescisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'DescisionTreeClassifier' from 'sklearn.ensemble' (/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Decision Tree Classifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Create and train the Decision Tree model\n","dt_model = DecisionTreeClassifier(random_state=2)\n","dt_model.fit(X_train, Y_train)\n","\n","# Make predictions on the test set\n","dt_test_prediction = dt_model.predict(X_test)\n","\n","# Calculate accuracy\n","dt_test_data_accuracy = accuracy_score(dt_test_prediction, Y_test)\n","print('Decision Tree Accuracy:', dt_test_data_accuracy)\n","\n","# Compare with Random Forest accuracy\n","print('Random Forest Accuracy:', test_data_accuracy)\n","\n","#Random Forest has more accuracy than Decision Tree so it is the best option"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYbsF3kkvZYl","executionInfo":{"status":"ok","timestamp":1718955680596,"user_tz":-330,"elapsed":430,"user":{"displayName":"SE_17_Charmi Jani","userId":"03847520836382925686"}},"outputId":"bb255413-e617-497c-f74b-0c7eea87b522"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Accuracy: 0.8423076923076923\n","Random Forest Accuracy: 0.8884615384615384\n"]}]}]}